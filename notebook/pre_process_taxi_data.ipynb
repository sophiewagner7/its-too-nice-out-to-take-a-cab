{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNHuzhD50P6a20HzcQxRObi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiewagner7/its-too-nice-out-to-take-a-cab/blob/main/notebook/pre_process_taxi_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Taxi Data\n",
        "\n",
        "Moacir P. de SÃ¡ Pereira\n",
        "\n",
        "This notebook reduces the size of our yellow taxi and high-volume for-hire vehicle (Uber, Lyft) data, downloaded from the [Taxi and Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). We drop columns that will not be important to us, rename the columns so that both yellow cab and FHVHV data will have the same column names, save `license`, which indicates which company operates the FHVHV trip in question. The codes convert to companies like this:\n",
        "\n",
        "Code | Company\n",
        "----|----\n",
        "HV0002|Juno\n",
        "HV0003|Uber\n",
        "HV0004|Via\n",
        "HV0005|Lyft\n",
        "\n",
        "Additionally, we use the taxi zone lookup table to reduce our trip data only to trips that originate and terminate in Manhattan. This has a substantial effect on the FHVHV data, but little effect on the yellow cab data.\n",
        "\n",
        "The files are then saved as parquet files in a `processed_files` folder.\n",
        "\n",
        "Next, the processed files are concatenated to make yearly files, saved in `concatenated_files`."
      ],
      "metadata": {
        "id": "1CC2WrR0Drck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ER18E9LRgFd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77d2a7b-d761-4026-c634-a247720b15f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = \"./drive/MyDrive/taxi-data\"\n",
        "\n",
        "zones_df = pd.read_csv(f\"{root_path}/taxi_zone_lookup.csv\")\n",
        "manhattan_zones = list(zones_df[zones_df.Borough == \"Manhattan\"].LocationID)\n",
        "\n",
        "yellow_columns_to_keep = {\n",
        "    \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
        "    \"tpep_dropoff_datetime\": \"dropoff_datetime\",\n",
        "    \"trip_distance\": \"trip_distance\",\n",
        "    \"PULocationID\": \"pickup_zone\",\n",
        "    \"DOLocationID\": \"dropoff_zone\",\n",
        "    \"fare_amount\": \"fare_amount\",\n",
        "    \"tip_amount\": \"tip_amount\"\n",
        "}\n",
        "\n",
        "fhvhv_columns_to_keep = {\n",
        "    \"pickup_datetime\": \"pickup_datetime\",\n",
        "    \"dropoff_datetime\": \"dropoff_datetime\",\n",
        "    \"trip_miles\": \"trip_distance\",\n",
        "    \"PULocationID\": \"pickup_zone\",\n",
        "    \"DOLocationID\": \"dropoff_zone\",\n",
        "    \"base_passenger_fare\": \"fare_amount\",\n",
        "    \"tips\": \"tip_amount\",\n",
        "    \"hvfhs_license_num\": \"license\",\n",
        "}\n",
        "\n",
        "license_relabel = {\n",
        "    \"yellow\": \"yellow\",\n",
        "    \"HV0002\": \"juno\",\n",
        "    \"HV0003\": \"uber\",\n",
        "    \"HV0004\": \"via\",\n",
        "    \"HV0005\": \"lyft\"\n",
        "}"
      ],
      "metadata": {
        "id": "B5cyBHFigMqi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(trip = \"fhvhv\", file_name = \"fhvhv_tripdata_2021-05.parquet\"):\n",
        "  path = f\"{root_path}/original_files/{file_name}\"\n",
        "  if trip == \"yellow\":\n",
        "    columns = yellow_columns_to_keep\n",
        "  else:\n",
        "    columns = fhvhv_columns_to_keep\n",
        "  df = pd.read_parquet(path)\n",
        "  df = df[columns.keys()]\n",
        "  df = df.rename(columns=columns)\n",
        "  df = df[df.pickup_zone.isin(manhattan_zones) & df.dropoff_zone.isin(manhattan_zones)]\n",
        "  df.to_parquet(f\"{root_path}/processed_files/{file_name}\")\n",
        "  return df"
      ],
      "metadata": {
        "id": "zgvZp4Juo677"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_files(trip=\"yellow\", year=2019):\n",
        "  starting_month = 1\n",
        "  if year == 2019 and trip == \"fhvhv\":\n",
        "    starting_month = 2\n",
        "\n",
        "  ending_month = 12\n",
        "  if year == 2024:\n",
        "    ending_month = 8\n",
        "\n",
        "  dfs = []\n",
        "  for month in tqdm(range(starting_month, ending_month + 1)):\n",
        "    path = f\"{root_path}/processed_files/{trip}_tripdata_{year}-{str(month).zfill(2)}.parquet\"\n",
        "    df_fragment = pd.read_parquet(path)\n",
        "    dfs.append(df_fragment)\n",
        "\n",
        "  df = pd.concat(dfs, ignore_index = True)\n",
        "  if trip == \"yellow\":\n",
        "    df[\"license\"] = \"yellow\"\n",
        "  df.to_parquet(f\"{root_path}/concatenated_files/{trip}_{year}.parquet\")\n",
        "  print(f\"Wrote {root_path}/concatenated_files/{trip}_{year}.parquet\")"
      ],
      "metadata": {
        "id": "mvAT8kKcGO2o"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for trip in [\"fhvhv\", \"yellow\"]:\n",
        "#   for year in range(2019, 2025):\n",
        "#     for month in range(12):\n",
        "#       if trip == \"fhvhv\" and year == 2019 and month == 0:\n",
        "#         # No file for FHVHV for January 2019.\n",
        "#         continue\n",
        "#       month = str(month + 1).zfill(2)\n",
        "#       file_name = f\"{trip}_tripdata_{year}-{month}.parquet\"\n",
        "#       print(f\"Working on {file_name}\")\n",
        "#       process_file(trip, file_name)\n"
      ],
      "metadata": {
        "id": "4ZFtYzxLnc0A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for trip in [\"fhvhv\", \"yellow\"]:\n",
        "#   for year in range(2020, 2025):\n",
        "#     concat_files(trip=trip, year=year)"
      ],
      "metadata": {
        "id": "O6px-UVdw90A"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_data(year=2024):\n",
        "  destination_path = f\"{root_path}/aggregated_hourly_files/{year}.parquet\"\n",
        "  yellow_df = pd.read_parquet(f\"{root_path}/concatenated_files/yellow_{year}.parquet\")\n",
        "  fhvhv_df = pd.read_parquet(f\"{root_path}/concatenated_files/fhvhv_{year}.parquet\")\n",
        "  df = pd.concat([yellow_df, fhvhv_df])\n",
        "  df = df[df.pickup_datetime.dt.year == year]\n",
        "  df[\"trip_duration\"] = df.dropoff_datetime - df.pickup_datetime\n",
        "  df = df[df.trip_duration.between(pd.Timedelta(minutes=1), pd.Timedelta(hours=2))]\n",
        "\n",
        "  df[\"date\"] = df.pickup_datetime.dt.date\n",
        "  df[\"hour\"] = df.pickup_datetime.dt.hour\n",
        "  df[\"license\"] = df[\"license\"].replace(license_relabel)\n",
        "\n",
        "  license_agg_df = df.groupby([\"date\", \"hour\", \"license\"]).size().unstack(fill_value=0)\n",
        "  agg_df = df.groupby([\"date\", \"hour\"]).agg(\n",
        "      trip_count=(\"trip_duration\", \"count\"),\n",
        "      trip_duration_mean=(\"trip_duration\", \"mean\"),\n",
        "      trip_duration_median=(\"trip_duration\", \"median\"),\n",
        "      trip_duration_std_dev=(\"trip_duration\", \"std\"),\n",
        "      trip_duration_1Q=(\"trip_duration\", lambda x: np.percentile(x, 25)),\n",
        "      trip_duration_3Q=(\"trip_duration\", lambda x: np.percentile(x, 75)),\n",
        "      trip_distance_mean=(\"trip_distance\", \"mean\"),\n",
        "      trip_distance_median=(\"trip_distance\", \"median\"),\n",
        "      trip_distance_std_dev=(\"trip_distance\", \"std\"),\n",
        "      trip_distance_1Q=(\"trip_distance\", lambda x: np.percentile(x, 25)),\n",
        "      trip_distance_3Q=(\"trip_distance\", lambda x: np.percentile(x, 75)),\n",
        "      fare_amount_mean=(\"fare_amount\", \"mean\"),\n",
        "      fare_amount_median=(\"fare_amount\", \"median\"),\n",
        "      fare_amount_std_dev=(\"fare_amount\", \"std\"),\n",
        "      fare_amount_1Q=(\"fare_amount\", lambda x: np.percentile(x, 25)),\n",
        "      fare_amount_3Q=(\"fare_amount\", lambda x: np.percentile(x, 75)),\n",
        "      tip_amount_mean=(\"tip_amount\", \"mean\"),\n",
        "      tip_amount_median=(\"tip_amount\", \"median\"),\n",
        "      tip_amount_std_dev=(\"tip_amount\", \"std\"),\n",
        "      tip_amount_1Q=(\"tip_amount\", lambda x: np.percentile(x, 25)),\n",
        "      tip_amount_3Q=(\"tip_amount\", lambda x: np.percentile(x, 75)),\n",
        "  ).reset_index()\n",
        "  merged_df = pd.merge(agg_df, license_agg_df, on=[\"date\", \"hour\"], how=\"inner\")\n",
        "  merged_df.to_parquet(destination_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "lUWmt620D8U7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for year in tqdm(range(2019, 2025)):\n",
        "  aggregate_data(year)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyaDTqhlEvaB",
        "outputId": "4a256403-c672-4b32-9812-49f663da392f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 6/6 [13:50<00:00, 138.37s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "\n",
        "for year in tqdm(range(2019, 2025)):\n",
        "  source_path = f\"{root_path}/aggregated_hourly_files/{year}.parquet\"\n",
        "  df_fragment = pd.read_parquet(source_path)\n",
        "  dfs.append(df_fragment)\n",
        "\n",
        "df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6i6LWQ79KBa",
        "outputId": "7395ec24-3885-4567-cc3e-222f33ef1fe0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 6/6 [00:00<00:00, 50.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[pd.to_datetime(df.date) < \"2024-06-26\"]\n",
        "df.reset_index()\n",
        "df.to_parquet(f\"{root_path}/complete_hourly.parquet\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZH7gIb6YRjuW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UnF1xqDWCXxR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}