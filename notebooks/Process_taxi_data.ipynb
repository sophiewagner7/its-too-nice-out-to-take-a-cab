{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMWU/hPgI+y2kk2JPFK2W/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiewagner7/its-too-nice-out-to-take-a-cab/blob/main/notebooks/Process_taxi_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Taxi Data\n",
        "\n",
        "Moacir P. de SÃ¡ Pereira\n",
        "\n",
        "This notebook reduces the size of our yellow taxi and high-volume for-hire vehicle (Uber, Lyft) data, downloaded from the [Taxi and Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). We drop columns that will not be important to us, rename the columns so that both yellow cab and FHVHV data will have the same column names, save `license`, which indicates which company operates the FHVHV trip in question. The codes convert to companies like this:\n",
        "\n",
        "Code | Company\n",
        "----|----\n",
        "HV0002|Juno\n",
        "HV0003|Uber\n",
        "HV0004|Via\n",
        "HV0005|Lyft\n",
        "\n",
        "Additionally, we use the taxi zone lookup table to reduce our trip data only to trips that originate and terminate in Manhattan. This has a substantial effect on the FHVHV data, but little effect on the yellow cab data.\n",
        "\n",
        "The files are then saved as parquet files in a `processed_files` folder.\n",
        "\n",
        "Next, the processed files are concatenated to make yearly files, saved in `concatenated_files`."
      ],
      "metadata": {
        "id": "1CC2WrR0Drck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER18E9LRgFd1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = \"./drive/MyDrive/taxi-data\"\n",
        "\n",
        "zones_df = pd.read_csv(f\"{root_path}/taxi_zone_lookup.csv\")\n",
        "manhattan_zones = list(zones_df[zones_df.Borough == \"Manhattan\"].LocationID)\n",
        "\n",
        "yellow_columns_to_keep = {\n",
        "    \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
        "    \"tpep_dropoff_datetime\": \"dropoff_datetime\",\n",
        "    \"trip_distance\": \"trip_distance\",\n",
        "    \"PULocationID\": \"pickup_zone\",\n",
        "    \"DOLocationID\": \"dropoff_zone\",\n",
        "    \"fare_amount\": \"fare_amount\",\n",
        "    \"tip_amount\": \"tip_amount\"\n",
        "}\n",
        "\n",
        "fhvhv_columns_to_keep = {\n",
        "    \"pickup_datetime\": \"pickup_datetime\",\n",
        "    \"dropoff_datetime\": \"dropoff_datetime\",\n",
        "    \"trip_miles\": \"trip_distance\",\n",
        "    \"PULocationID\": \"pickup_zone\",\n",
        "    \"DOLocationID\": \"dropoff_zone\",\n",
        "    \"base_passenger_fare\": \"fare_amount\",\n",
        "    \"tips\": \"tip_amount\",\n",
        "    \"hvfhs_license_num\": \"license\",\n",
        "}"
      ],
      "metadata": {
        "id": "B5cyBHFigMqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(trip = \"fhvhv\", file_name = \"fhvhv_tripdata_2021-05.parquet\"):\n",
        "  path = f\"{root_path}/{file_name}\"\n",
        "  if trip == \"yellow\":\n",
        "    columns = yellow_columns_to_keep\n",
        "  else:\n",
        "    columns = fhvhv_columns_to_keep\n",
        "  df = pd.read_parquet(path)\n",
        "  df = df[columns.keys()]\n",
        "  df = df.rename(columns=columns)\n",
        "  df = df[df.pickup_zone.isin(manhattan_zones) & df.dropoff_zone.isin(manhattan_zones)]\n",
        "  df.to_parquet(f\"{root_path}/processed_files/{file_name}\")\n",
        "  return df"
      ],
      "metadata": {
        "id": "zgvZp4Juo677"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_files(trip=\"yellow\", year=2019):\n",
        "  starting_month = 1\n",
        "  if year == 2019 and trip == \"fhvhv\":\n",
        "    starting_month = 2\n",
        "\n",
        "  ending_month = 12\n",
        "  if year == 2024:\n",
        "    ending_month = 8\n",
        "\n",
        "  df = pd.DataFrame()\n",
        "  for month in tqdm(range(starting_month, ending_month + 1)):\n",
        "    path = f\"{root_path}/processed_files/{trip}_tripdata_{year}-{str(month).zfill(2)}.parquet\"\n",
        "    df_fragment = pd.read_parquet(path)\n",
        "    df = pd.concat([df, df_fragment], ignore_index = True)\n",
        "  if trip == \"yellow\":\n",
        "    df[\"license\"] = \"yellow\"\n",
        "  df.to_parquet(f\"{root_path}/concatenated_files/{trip}_{year}.parquet\")\n",
        "  print(f\"Wrote {root_path}/concatenated_files/{trip}_{year}.parquet\")"
      ],
      "metadata": {
        "id": "mvAT8kKcGO2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for trip in [\"fhvhv\", \"yellow\"]:\n",
        "  for year in range(2019, 2025):\n",
        "    for month in range(12):\n",
        "      if trip == \"fhvhv\" and year == 2019 and month == 0:\n",
        "        # No file for FHVHV for January 2019.\n",
        "        continue\n",
        "      month = str(month + 1).zfill(2)\n",
        "      file_name = f\"{trip}_tripdata_{year}-{month}.parquet\"\n",
        "      print(f\"Working on {file_name}\")\n",
        "      process_file(trip, file_name)\n"
      ],
      "metadata": {
        "id": "4ZFtYzxLnc0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for trip in [\"fhvhv\", \"yellow\"]:\n",
        "  for year in range(2020, 2025):\n",
        "    concat_files(trip=trip, year=year)"
      ],
      "metadata": {
        "id": "O6px-UVdw90A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}